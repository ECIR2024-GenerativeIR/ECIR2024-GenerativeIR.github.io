<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SIGIR-AP 2023 Tutorial: Recent Advances in Generative Information Retrieval</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">
              <span style="font-size: 80%">SIGIR-AP 2023 Tutorial:</span><br />
              Recent Advances in Generative Information Retrieval
            </h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <table>
            <tr>
                <!-- <th scope="row">TR-7</th> -->
                <td width="25%" style="text-align: center; padding: 10px"><img width="150px" height="150px" src="static/imgs/profile_tangyubao.jpg"></td>
                <td width="25%" style="text-align: center; padding: 10px"><img width="150px" height="150px" src="static/imgs/profile_ruqing.jpg"></td>
                <td width="25%" style="text-align: center; padding: 10px"><img width="150px" height="150px" src="static/imgs/profile_jiafeng.jpg"></td>
                <td width="25%" style="text-align: center; padding: 10px"><img width="150px" height="150px" src="static/imgs/profile_mdr.jpg"></td>
            </tr>
              <tr>
                <!-- <th scope="row">TR-7</th> -->
                <td width="25%" style="text-align: center"><a href="https://github.com/lightningtyb" style="border-radius: 50%">Yubao Tang</a><sup>1</sup>,</td>
                <td width="25%" style="text-align: center"><a href="https://daqingchong.github.io/" style="border-radius: 50%">Ruqing Zhang</a><sup>1</sup>,</td>
                <td width="25%" style="text-align: center"><a href="http://www.bigdatalab.ac.cn/gjf/" style="border-radius: 50%">Jiafeng Guo</a><sup>1</sup>,</td>
                <td width="25%" style="text-align: center"><a href="https://staff.fnwi.uva.nl/m.derijke/" style="border-radius: 50%">Maarten de Rijke</a><sup>2</sup></td>
              </tr>
            </table>
            </span>
          </div>
          <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>1</sup>CAS Key Lab of Network Data Science and Technology, ICT, CAS, University of Chinese Academy of Sciences, </span>
            <span class="author-block"><sup>2</sup>University of Amsterdam</span>
          </div>
          <br />
          <div class="is-size-5 publication-authors">
            <b>Sunday November 26 13:00 - 16:30 (GMT+8) @ Rm1</b>
          </div>
          <!-- <div class="is-size-5 publication-authors">
            Zoom link available on <a href="https://underline.io/events/395/sessions?eventSessionId=15330&searchGroup=lecture" target="_blank">Underline</a>
          </div> -->
        </div>
      </div>
    </div>
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">About this tutorial</h2>
        <div class="content has-text-justified">
          <p>
            Generative retrieval (GR) has become a highly active area of information retrieval (IR) that has witnessed significant growth recently.
            Compared to the traditional ``index-retrieve-then-rank'' pipeline, the GR paradigm aims to consolidate all information within a corpus into a single model.
            Typically, a sequence-to-sequence model is trained to directly map a query to its relevant document identifiers (i.e., docids).
            This tutorial offers an introduction to the core concepts of the GR paradigm and a comprehensive overview of recent advances in its foundations and applications.
          </p>
          <p>
            We start by providing preliminary information covering foundational aspects and problem formulations of GR.
            Then, our focus shifts towards recent progress in docid design, training approaches, inference strategies, and the applications of GR.
            We end by outlining remaining challenges and issuing a call for future GR research.
            This tutorial is intended to be beneficial to both researchers and industry practitioners interested in developing novel GR solutions or applying them in real-world scenarios.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Schedule</h2>
        <p>
          Our tutorial will be held on November 26 13:00 - 16:30 (GMT+8).
          <em>Slides may be subject to updates.</em>
        </p>

        <div class="content has-text-justified">

          <style type="text/css">
          .tg  {border-collapse:collapse;border-spacing:0;}
          .tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
            overflow:hidden;padding:10px 5px;word-break:normal;}
          .tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
            font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
          .tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
          .tg .tg-0lax{text-align:left;vertical-align:top}
          </style>
          <table class="tg">
          <thead>
            <tr>
              <th class="tg-0pky">Time</th>
              <th class="tg-0lax">Section</th>
              <th class="tg-0lax">Presenter</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="tg-0lax">14:00—14:10</td>
              <td class="tg-0lax">Section 1: Introduction  <a href="./slides/1-intro.pdf" target='_blank'>[Slides]</a></td>
              <td class="tg-0lax">test</td>
            </tr>
            <tr>
              <td class="tg-0lax">14:10—14:25</td>
              <td class="tg-0lax">Section 2: Definition & Preliminaries  <a href="./slides/2-definition.pdf" target='_blank'>[Slides]</a></td>
              <td class="tg-0lax">test</td>
            </tr>
            <tr>
              <td class="tg-0lax">14:25—15:20</td>
              <td class="tg-0lax">Section 3: Docid designs</td>
              <td class="tg-0lax">test</td>
            </tr>
            <tr>
              <td class="tg-0lax">15:20—15:40</td>
              <td class="tg-0lax">20min coffee break</td>
              <td class="tg-0lax"></td>
            </tr>
            <tr>
              <td class="tg-0lax">15:40—15:55</td>
              <td class="tg-0lax">Section 3: Docid designs</td>
              <td class="tg-0lax">test</td>
            </tr>
            <tr>
              <td class="tg-0lax">15:55—16:15</td>
              <td class="tg-0lax">Section 4: Training approaches</td>
              <td class="tg-0lax">test</td>
            </tr>
            <tr>
              <td class="tg-0lax">16:15—16:30</td>
              <td class="tg-0lax">Section 5: Inference strategies  <a href="./slides/3-xxx.pdf" target='_blank'>[Slides]</a></td>
              <td class="tg-0lax">test</td>
            </tr>
            <tr>
              <td class="tg-0lax">16:30—16:40</td>
              <td class="tg-0lax">Section 6: Applications</td>
              <td class="tg-0lax"></td>
            </tr>
            <tr>
              <td class="tg-0lax">16:40—16:50</td>
              <td class="tg-0lax">Section 7: Challenges & Opportunities</td>
              <td class="tg-0lax"></td>
            </tr>
            <tr>
              <td class="tg-0lax">16:50—17:00</td>
              <td class="tg-0lax">Q & A</td>
              <td class="tg-0lax"></td>
            </tr>
          </tbody>
          </table>
        </div>
      </div>
    </div>

    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Reading List</h2>

        <p><b>Bold papers</b> are discussed in detail during our tutorial.</p>

        <br />
        
        
        <h3 class="title is-5">Section 3: Docid design</h3>

        <h4 class="title is-5">A single docid: Number-based</h4>
        <p><b>Unstructured atomic integers</b></pp>
        <ul>
          <li><a href="https://arxiv.org/pdf/2202.06991.pdf"><b>Transformer Memory as a Differentiable Search Index</b></a> (Tay et al. 2022)</li>
          <li><a href="https://arxiv.org/pdf/2203.00537.pdf">DynamicRetriever: A Pre-trained Model-based IR System Without an Explicit Index</a> (Zhou et al. 2023)</li>
          <li><a href="https://arxiv.org/pdf/2306.11397.pdf">Generative Retrieval as Dense Retrieval</a> (Nguyen and Yates et al. 2023c)</li>
          <li><a href="https://arxiv.org/pdf/2208.09257.pdf">Ultron: An ultimate retriever on corpus with a model-based indexer</a> (Zhou et al. 2022)</li>
          <li><a href="https://arxiv.org/pdf/2210.00328.pdf">CodeDSI: Differentiable Code Search</a> (Nadeem et al. 2022)</li>
          <li><a href="https://arxiv.org/pdf/2212.09744.pdf">DSI++: Updating Transformer Memory with New Documents</a> (Mehta et al. 2022)</li>
        </ul>

        <br />
        <p><b>Naively structured strings</b></pp>

          <ul>
            <li><a href="https://arxiv.org/pdf/2202.06991.pdf"><b>Transformer Memory as a Differentiable Search Index</b></a> (Tay et al. 2022)</li>
            <li><a href="https://arxiv.org/pdf/2206.10128.pdf">Bridging the Gap between Indexing and Retrieval for Differentiable Search Index with Query Generation</a> (Zhuang et al. 2023)</li>
            <li><a href="https://arxiv.org/pdf/2210.00328.pdf">CodeDSI: Differentiable Code Search</a> (Nadeem et al. 2022)</li>
         </ul>
         <br />
         <p><b>Semantically structured strings</b></pp>
          <ul>
            <li><a href="https://arxiv.org/pdf/2202.06991.pdf"><b>Transformer Memory as a Differentiable Search Index</b></a> (Tay et al. 2022)</li>
            <li><a href="https://arxiv.org/pdf/2206.02743.pdf">A Neural Corpus Indexer for Document Retrieval</a> (Wang et al. 2022)</li>
            <li><a href="https://arxiv.org/pdf/2305.02073.pdf">Understanding Differential Search Index for Text Retrieval</a> (Chen et al. 2023b)            </li>
            <li><a href="https://arxiv.org/pdf/2210.00328.pdf">CodeDSI: Differentiable Code Search</a> (Nadeem et al. 2022)</li>
          </ul>
          <br />
          <p><b> Product quantization strings</b></pp>
            <ul>
              <li><a href="https://arxiv.org/pdf/2208.09257.pdf"><b>Ultron: An ultimate retriever on corpus with a model-based indexer</b></a> (Zhou et al. 2022)</li>
              <li><a href="https://arxiv.org/pdf/2308.14968.pdf">Continual Learning for Generative Retrieval over Dynamic Corpora</a> (Chen et al. 2023a)</li>
              <li><a href="https://arxiv.org/pdf/2305.05065.pdf">Recommender Systems with Generative Retrieval</a> (Rajput et al. 2023)</li>
            </ul>

        <br />
        <h4 class="title is-5">A single docid: Word-based</h4>
        <p><b> Titles</b></pp>
          <ul>
            <li><a href="https://arxiv.org/pdf/2010.00904"><b>Autoregressive Entity Retrieval</b></a> (De Cao et al. 2021) </li>
            <li><a href="https://arxiv.org/pdf/2208.07652">CorpusBrain: Pre-train a Generative Retrieval Model for Knowledge-Intensive Language Tasks</a> (Chen et al. 2022b)</li>
            <li><a href="https://arxiv.org/pdf/2204.05511">GERE: Generative evidence retrieval for fact verification</a> (Chen et al. 2022a)</li>
            <li><a href="https://arxiv.org/pdf/2211.09388">Data-efficient Autoregressive Document Retrieval for Fact Verification</a> (Thorne et al. 2022)</li>
            <li><a href="https://arxiv.org/pdf/2208.09257.pdf">Ultron: An ultimate retriever on corpus with a model-based indexer</a> (Zhou et al. 2022)</li>
            <li><a href="https://arxiv.org/pdf/2204.13596.pdf">Generative Multi-hop Retrieval</a> (Lee et al. 2022)</li>
            <li><a href="https://arxiv.org/pdf/2210.02068.pdf">Nonparametric Decoding for Generative Retrieval</a> (Lee et al. 2023)</li>
            <li><a href="https://arxiv.org/pdf/2305.16675">Multiview Identifiers Enhanced Generative Retrieval</a> (Li et al. 2023)</li>
          </ul>
          <br />
          <p><b> URLs</b></pp>
            <ul>
              <li><a href="https://arxiv.org/pdf/2208.09257.pdf"><b>Ultron: An ultimate retriever on corpus with a model-based indexer</b></a> (Zhou et al. 2022)</li>
              <li><a href="https://arxiv.org/pdf/2305.11161"><b>TOME: A Two-stage Approach for Model-based Retrieval</b></a> (Ren et al. 2023)</li>
              <li><a href="https://arxiv.org/pdf/2211.09388">Data-efficient Autoregressive Document Retrieval for Fact Verification</a> (Thorne et al. 2022)</li>
             </ul>
          <br />
          <p><b> Pseudo queries</b></pp>
          <ul>
            <li><a href="https://arxiv.org/pdf/2305.15115"><b>Semantic-Enhanced Differentiable Search Index Inspired by Learning Strategies</b></a> (Tang et al. 2023a) </li>
            <li><a href="https://arxiv.org/pdf/2305.16675">Multiview Identifiers Enhanced Generative Retrieval</a>(Li et al. 2023)</li>
            </ul>
            <br />
          <p><b> Important terms</b></pp>
            <ul>
              <li><a href="https://arxiv.org/pdf/2305.13859"><b>Term-Sets Can Be Strong Document Identifiers For Auto-Regressive Search Engines</b></a> (Zhang et al. 2023) </li>
            </ul>
        <br />
        <h4 class="title is-5">Multiple docids: Single type (N-garms)</h4> 
        <ul>
          <li><a href="https://arxiv.org/pdf/2204.10628"><b>Autoregressive Search Engines: Generating Substrings as Document Identifiers</b></a> (Bevilacqua et al. 2022) </li>
          <li><a href="https://arxiv.org/pdf/2304.14856"><b>A Unified Generative Retriever for Knowledge-Intensive Language Tasks via Prompt Learning</b></a> (Chen et al. 2023b)</li>
          </ul>
          <br />
        <h4 class="title is-5">Multiple docids: Diverse types</h4>
        <ul>
          <li><a href="https://arxiv.org/pdf/2305.16675"><b>Multiview Identifiers Enhanced Generative Retrieval</b></a> (Li et al. 2023)</li>
          </ul>
          <br />

        <h3 class="title is-5">Section 4: Training approaches</h3>
        <h4 class="title is-5">Stationary scenarios</h4>
        <p><b> Supervised learning</b></pp>
          <ul>
            <li><a href="https://arxiv.org/pdf/2202.06991.pdf"><b>Transformer Memory as a Differentiable Search Index</b></a> (Tay et al. 2022)</li>
            <li><a href="https://arxiv.org/pdf/2305.15115"><b>Semantic-Enhanced Differentiable Search Index Inspired by Learning Strategies</b></a> (Tang et al. 2023a) </li>
            <li><a href="https://arxiv.org/pdf/2206.10128.pdf"><b>Bridging the Gap between Indexing and Retrieval for Differentiable Search Index with Query Generation</b></a> (Zhuang et al. 2023)</li>
            <li><a href="https://arxiv.org/pdf/2206.02743.pdf">A Neural Corpus Indexer for Document Retrieval</a> (Wang et al. 2022)</li>
            </ul>
            <br />
        <p><b> Pre-training</b></pp>
          <ul>
            <li><a href="https://arxiv.org/pdf/2208.07652"><b>CorpusBrain: Pre-train a Generative Retrieval Model for Knowledge-Intensive Language Tasks</b></a> (Chen et al. 2022b)</li>
        </ul>

        <br />
        <h4 class="title is-5">Dynamic scenarios</h4>
        <ul>
          <li><a href="https://arxiv.org/pdf/2212.09744.pdf"><b>DSI++: Updating Transformer Memory with New Documents</b></a> (Mehta et al. 2022)</li>
          <li><a href="https://arxiv.org/pdf/2308.14968.pdf"><b>Continual Learning for Generative Retrieval over Dynamic Corpora</b></a> (Chen et al. 2023a)</li>

      </ul>
       
       
        <br />

        <h3 class="title is-5">Section 5: Inference strategies</h3>
        <p><b> Constrained beam search with prefix tree</b></pp>
          <ul>
            <li><a href="https://arxiv.org/pdf/2010.00904"><b>Autoregressive Entity Retrieval</b></a> (De Cao et al. 2021) </li>
           </ul>
           <br />
           <p><b> Constrained greedy search with inverted index</b></pp>
            <ul>
              <li><a href="https://arxiv.org/pdf/2305.13859"><b>Term-Sets Can Be Strong Document Identifiers For Auto-Regressive Search Engines</b></a> (Zhang et al. 2023) </li>
            </ul>
            <br />
            <p><b> Constrained beam search with FM-index</b></pp>
              <ul>
                <li><a href="https://arxiv.org/pdf/2204.10628"><b>Autoregressive Search Engines: Generating Substrings as Document Identifiers</b></a> (Bevilacqua et al. 2022) </li>
              </ul>

        <h3 class="title is-5">Section 6: Applications</h3>
        <p><b> KILT</b></pp>
          <ul>
            <li><a href="https://arxiv.org/pdf/2010.00904"><b>Autoregressive Entity Retrieval</b></a> (De Cao et al. 2021) </li>
            <li><a href="https://arxiv.org/pdf/2204.05511"><b>GERE: Generative evidence retrieval for fact verification</b></a> (Chen et al. 2022a)</li>
            <li><a href="https://arxiv.org/pdf/2204.10628">Autoregressive Search Engines: Generating Substrings as Document Identifiers</a> (Bevilacqua et al. 2022) </li>
            <li><a href="https://arxiv.org/pdf/2304.14856">A Unified Generative Retriever for Knowledge-Intensive Language Tasks via Prompt Learning</a> (Chen et al. 2023b)</li>
            <li><a href="https://arxiv.org/pdf/2208.07652">CorpusBrain: Pre-train a Generative Retrieval Model for Knowledge-Intensive Language Tasks</a> (Chen et al. 2022b)</li>
            <li><a href="https://arxiv.org/pdf/2211.09388">Data-efficient Autoregressive Document Retrieval for Fact Verification</a> (Thorne et al. 2022)</li>

          </ul>
            <br />
            <p><b> Multi-hop retrieval</b></pp>
            <ul>
              <li><a href="https://arxiv.org/pdf/2204.13596.pdf"><b>Generative Multi-hop Retrieval</b></a> (Lee et al. 2022)</li>
            </ul>
            <br />
            <p><b> Recommendation</b></pp>
              <ul>
                <li><a href="https://arxiv.org/pdf/2305.05065.pdf"><b>Recommender Systems with Generative Retrieval</b></a> (Rajput et al. 2023)</li>
                <li><a href="https://arxiv.org/pdf/2309.13375.pdf">Generative Retrieval with Semantic Tree-Structured Item Identifiers via Contrastive Learning</a> (Si et al. 2023 )</li>
              </ul>
              <br />
            <p><b> Code retrieval</b></pp>
              <ul>
                <li><a href="https://arxiv.org/pdf/2210.00328.pdf"><b>CodeDSI: Differentiable Code Search</b></a> (Nadeem et al. 2022)</li>
              </ul>
      </div>
    </div>



    <br />
    <!--Code -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Available code</h2>
        <ul>
          <li><a href="https://github.com/facebookresearch/GENRE">Autoregressive Entity Retrieval</a> (De Cao et al. 2021) </li>
          <li><a href="https://github.com/ict-bigdatalab/CorpusBrain">CorpusBrain: Pre-train a Generative Retrieval Model for Knowledge-Intensive Language Tasks</a> (Chen et al. 2022b)</li>
          <li><a href="https://github.com/Chriskuei/GERE">GERE: Generative evidence retrieval for fact verification</a> (Chen et al. 2022a)</li>
          <li><a href="https://github.com/ facebookresearch/SEAL">Autoregressive Search Engines: Generating Substrings as Document Identifiers</a> (Bevilacqua et al. 2022) </li>
          <li><a href="https://github.com/liyongqi67/MINDER">Multiview Identifiers Enhanced Generative Retrieval</a> (Li et al. 2023)</li>
          <li><a href="https://github.com/ict-bigdatalab/CLEVER">Continual Learning for Generative Retrieval over Dynamic Corpora</a> (Chen et al. 2023a)</li>
          <li><a href="https://github.com/amy-hyunji/Contextualized-Generative-Retrieval">Nonparametric Decoding for Generative Retrieval</a> (Lee et al. 2023)</li>
          <li><a href="https://github.com/ ArvinZhuang/DSI-QG">Bridging the Gap between Indexing and Retrieval for Differentiable Search Index with Query Generation</a> (Zhuang et al. 2023)</li>
          <li><a href="https://github.com/solidsea98/Neural-Corpus-Indexer-NCI">A Neural Corpus Indexer for Document Retrieval</a> (Wang et al. 2022)</li>
          <li><a href="https://github.com/ict-bigdatalab/UGR">A Unified Generative Retriever for Knowledge-Intensive Language Tasks via Prompt Learning</a> (Chen et al. 2023b)</li>
          <li><a href="https://github.com/VerdureChen/Understanding_DSI">Understanding Differential Search Index for Text Retrieval</a> (Chen et al. 2023b)</li>
          <li><a href="https://github.com/amy-hyunji/Generative-MultihopRetrieval">Generative Multi-hop Retrieval</a> (Lee et al. 2022)</li>
        </ul>

        <br />


        

      
      </div>
    </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{tang-2023-recent,
      author = {Tang, Yubao and Zhang, Ruqing and Guo, Jiafeng and de Rijke, Maarten},
      booktitle = {SIGIR-AP 2023: 1st International ACM SIGIR Conference on Information Retrieval in the Asia Pacific},
      date-added = {2023-10-07 17:24:48 +0200},
      date-modified = {2023-10-07 17:26:24 +0200},
      month = {November},
      publisher = {ACM},
      title = {Recent Advances in Generative Information Retrieval},
      year = {2023}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/ACL2023-Retrieval-LM" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
